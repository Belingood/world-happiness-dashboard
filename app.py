# --- 1. IMPORT BIBLIOTEK ---
import streamlit as st
import pandas as pd
import plotly.express as px
import seaborn as sns
import matplotlib.pyplot as plt
import os
from thefuzz import process
import statsmodels.api as sm

# --- 2. KONFIGURACJA STRONY ---
st.set_page_config(page_title="Analiza World Happiness Report", page_icon="ğŸ˜Š", layout="wide")


# --- 3. FUNKCJE POMOCNICZE ---
# Funkcja standardize_columns pozostaje bez zmian
def standardize_columns(dataframe):
    df_original = dataframe.copy()
    rename_map = {
        'Country': ['country'], 'Region': ['regional indicator'],
        'Happiness Score': ['happiness score', 'ladder score'], 'GDP per capita': ['gdp per capita'],
        'Social Support': ['social support'], 'Life Expectancy': ['healthy life expectancy'],
        'Freedom': ['freedom to make life choices'], 'Generosity': ['generosity'],
        'Corruption': ['perceptions of corruption']
    }
    df_clean = pd.DataFrame()
    processed_original_cols = set()
    for standard_name, keywords in rename_map.items():
        best_match_col = None
        for col_original in df_original.columns:
            if col_original in processed_original_cols: continue
            if col_original.lower().strip().startswith("explained by:"):
                col_clean = col_original.lower().replace('explained by: ', '').strip()
                if any(keyword in col_clean for keyword in keywords):
                    best_match_col = col_original
                    break
        if not best_match_col:
            for col_original in df_original.columns:
                if col_original in processed_original_cols: continue
                col_clean = col_original.lower().strip()
                if any(keyword in col_clean for keyword in keywords):
                    best_match_col = col_original
                    break
        if best_match_col:
            df_clean[standard_name] = df_original[best_match_col]
            processed_original_cols.add(best_match_col)
    for col in df_original.columns:
        if col not in processed_original_cols:
            df_clean[col] = df_original[col]
    return df_clean


@st.cache_data
def load_lookup_data():
    try:
        lookup_path = os.path.join('data', 'country_region_lookup.csv')
        df_lookup = pd.read_csv(lookup_path)
        df_lookup.dropna(subset=['region'], inplace=True)
        return df_lookup
    except FileNotFoundError:
        st.error("Plik referencyjny 'data/country_region_lookup.csv' nie zostaÅ‚ znaleziony!")
        return None


# --- 4. TYTUÅ I OPIS APLIKACJI ---
st.title('ğŸ˜Š Interaktywny Dashboard: Analiza Åšwiatowego Raportu SzczÄ™Å›cia')
st.write("Aplikacja do wizualizacji i analizy danych z raportu 'World Happiness Report'.")
st.markdown("---")

# --- 5. PRZESYÅANIE PLIKU ---
st.markdown("### Krok 1: PrzeÅ›lij plik z danymi")
uploaded_file = st.file_uploader("Wybierz plik CSV", type="csv")

# Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ session_state Ğ¿Ñ€Ğ¸ Ğ¿ĞµÑ€Ğ²Ğ¾Ğ¹ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞµ
if 'data_cleaned' not in st.session_state:
    st.session_state.data_cleaned = False

# Ğ¡Ğ±Ñ€Ğ¾Ñ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¸ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞµ Ğ½Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ğ°
if uploaded_file and uploaded_file.name != st.session_state.get('last_file_name', ''):
    st.session_state.data_cleaned = False
    st.session_state.last_file_name = uploaded_file.name

if uploaded_file is not None:
    df_lookup = load_lookup_data()

    if df_lookup is not None:
        # --- ETAP 1: PRZETWARZANIE WSTÄ˜PNE ---
        df_raw = pd.read_csv(uploaded_file)
        df_processed = standardize_columns(df_raw)

        canonical_names = df_lookup['canonical_name'].tolist()

        # Automatyczne mapowanie
        unmatched_countries = []
        mapping = {}
        for country in df_processed['Country'].dropna().unique():
            cleaned_name = country.replace('*', '').strip()
            match = process.extractOne(cleaned_name, canonical_names, score_cutoff=90)
            if match:
                mapping[country] = match[0]
            else:
                unmatched_countries.append(country)

        df_processed['canonical_name'] = df_processed['Country'].map(mapping)

        # --- ETAP 2: INTERAKTYWNE REWIZJA (JEÅšLI POTRZEBNE) ---
        if unmatched_countries and not st.session_state.data_cleaned:
            with st.expander("âš ï¸ PrzeglÄ…d Nierozpoznanych KrajÃ³w - Wymagana Akcja!", expanded=True):
                st.warning(
                    "Nie udaÅ‚o siÄ™ automatycznie dopasowaÄ‡ wszystkich krajÃ³w. ProszÄ™, zweryfikuj poniÅ¼sze propozycje.")

                user_choices = {}
                for country in unmatched_countries:
                    cleaned_name = country.replace('*', '').strip()
                    best_guesses = [guess[0] for guess in process.extract(cleaned_name, canonical_names, limit=3)]
                    options = best_guesses + ["(PomiÅ„ / Pozostaw oryginalnÄ… nazwÄ™)"]

                    user_choices[country] = st.selectbox(
                        f"Wybierz poprawne dopasowanie Ğ´Ğ»Ñ **'{country}'**:",
                        options, index=0, key=f"select_{country}"
                    )

                if st.button("Zastosuj i zweryfikuj poprawki"):
                    # Budujemy finalne mapowanie
                    final_mapping = mapping.copy()
                    for original, choice in user_choices.items():
                        if choice != "(PomiÅ„ / Pozostaw oryginalnÄ… nazwÄ™)":
                            final_mapping[original] = choice

                    # --- ĞĞĞ’Ğ«Ğ™ Ğ‘Ğ›ĞĞš: ĞŸĞ ĞĞ’Ğ•Ğ ĞšĞ ĞĞ ĞšĞĞĞ¤Ğ›Ğ˜ĞšĞ¢Ğ« ---
                    chosen_canonical_names = list(final_mapping.values())
                    counts = pd.Series(chosen_canonical_names).value_counts()
                    duplicates = counts[counts > 1]

                    if not duplicates.empty:
                        st.error(
                            "Wykryto konflikt! Kilka rÃ³Å¼nych krajÃ³w zostaÅ‚o zmapowanych do tej samej nazwy kanonicznej. ProszÄ™ poprawiÄ‡ swÃ³j wybÃ³r.")
                        for dup_name, count in duplicates.items():
                            conflicting_originals = [orig for orig, can in final_mapping.items() if can == dup_name]
                            st.write(
                                f"- Nazwa **'{dup_name}'** zostaÅ‚a wybrana dla: `{', '.join(conflicting_originals)}`")
                    else:
                        # Ğ•ÑĞ»Ğ¸ ĞºĞ¾Ğ½Ñ„Ğ»Ğ¸ĞºÑ‚Ğ¾Ğ² Ğ½ĞµÑ‚, Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ÑĞµĞ¼ Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ
                        df_processed['canonical_name'] = df_processed['Country'].map(final_mapping)
                        st.session_state['data_cleaned'] = True
                        st.success("Poprawki zostaÅ‚y pomyÅ›lnie zastosowane! Brak konfliktÃ³w.")
                        st.rerun()  # ĞŸĞµÑ€ĞµĞ·Ğ°Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ ÑĞºÑ€Ğ¸Ğ¿Ñ‚, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ ÑĞºÑ€Ñ‹Ñ‚ÑŒ ÑÑ‚Ğ¾Ñ‚ Ğ±Ğ»Ğ¾Ğº Ğ¸ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹

        else:  # Ğ•ÑĞ»Ğ¸ Ğ²ÑĞµ zmapowano Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ¸Ğ»Ğ¸ ÑƒĞ¶Ğµ Ğ¸ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¾
            st.session_state.data_cleaned = True

        # --- ETAP 3: FINALIZACJA I WIZUALIZACJA (TYLKO GDY DANE SÄ„ GOTOWE) ---
        if st.session_state.data_cleaned:
            df_processed['canonical_name'].fillna(df_processed['Country'], inplace=True)

            if 'Region' in df_processed.columns:
                df_processed = df_processed.drop(columns=['Region'])

            df_enriched = pd.merge(df_processed, df_lookup, on='canonical_name', how='left')
            df_enriched['Country'] = df_enriched['canonical_name']
            df_enriched.rename(columns={'region': 'Region'}, inplace=True)
            df_enriched.drop(columns=['canonical_name'], inplace=True)
            df_enriched['Region'].fillna('Brak danych', inplace=True)

            if not unmatched_countries:  # ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ ĞµÑĞ»Ğ¸ Ğ½Ğµ Ğ±Ñ‹Ğ»Ğ¾ Ñ€ÑƒÑ‡Ğ½Ğ¾Ğ³Ğ¾ Ñ€ĞµĞ²ÑŒÑ
                st.success("Dane zaÅ‚adowane, przetworzone i gotowe do analizy!")

            df_processed = df_enriched

            st.header("Etap 2: Analiza Danych")
            st.subheader("ObsÅ‚uga brakujÄ…cych wartoÅ›ci")
            # ... (Ğ¾ÑÑ‚Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ñ‡Ğ°ÑÑ‚ÑŒ ĞºĞ¾Ğ´Ğ° Ğ±ĞµĞ· Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹) ...
            missing_values = df_processed.isnull().sum()
            missing_values = missing_values[missing_values > 0]
            if not missing_values.empty:
                st.warning("Wykryto brakujÄ…ce dane! Tabela poniÅ¼ej pokazuje problematyczne wpisy.")
                rows_with_missing = df_processed[df_processed.isnull().any(axis=1)]
                cols_with_missing = missing_values.index.tolist()
                if 'Country' in df_processed.columns and 'Country' not in cols_with_missing:
                    cols_with_missing.insert(0, 'Country')
                st.dataframe(rows_with_missing[cols_with_missing].reset_index(drop=True))
                strategy = st.radio("Wybierz strategiÄ™:",
                                    ('UzupeÅ‚nij medianÄ… (zalecane)', 'UzupeÅ‚nij Å›redniÄ…', 'UsuÅ„ wiersze z brakami'))
                df_cleaned = df_processed.copy()
                for col in missing_values.index:
                    if pd.api.types.is_numeric_dtype(df_cleaned[col]):
                        if strategy == 'UzupeÅ‚nij medianÄ… (zalecane)':
                            df_cleaned[col].fillna(df_cleaned[col].median(), inplace=True)
                        elif strategy == 'UzupeÅ‚nij Å›redniÄ…':
                            df_cleaned[col].fillna(df_cleaned[col].mean(), inplace=True)
                if strategy == 'UsuÅ„ wiersze z brakami': df_cleaned.dropna(inplace=True)
                st.success(f"Zastosowano strategiÄ™: **{strategy}**. Dane oczyszczone.")
            else:
                st.info("W danych nie znaleziono brakujÄ…cych wartoÅ›ci.")
                df_cleaned = df_processed.copy()

            st.sidebar.header("Opcje filtrowania")
            if 'Region' in df_cleaned.columns and df_cleaned['Region'].nunique() > 1:
                all_regions = sorted([str(region) for region in df_cleaned['Region'].unique() if pd.notna(region)])
                selected_regions = st.sidebar.multiselect("Wybierz regiony:", options=all_regions, default=all_regions)
                df_filtered = df_cleaned[df_cleaned['Region'].isin(selected_regions)]
            else:
                df_filtered = df_cleaned

            st.subheader("Tabela danych")
            st.dataframe(df_filtered, height=400)

            st.subheader("Mapa wskaÅºnika szczÄ™Å›cia na Å›wiecie")
            fig_map = px.choropleth(df_filtered, locations='Country', locationmode='country names',
                                    color='Happiness Score', hover_name='Country',
                                    color_continuous_scale=px.colors.sequential.Plasma,
                                    title='Poziom szczÄ™Å›cia w poszczegÃ³lnych krajach')
            st.plotly_chart(fig_map, use_container_width=True)

            st.subheader("ZaleÅ¼noÅ›Ä‡ poziomu szczÄ™Å›cia od PKB per capita")
            fig_scatter = px.scatter(df_filtered, x='GDP per capita', y='Happiness Score', hover_name='Country',
                                     title='ZaleÅ¼noÅ›Ä‡ wskaÅºnika szczÄ™Å›cia od PKB per capita', trendline='ols')
            st.plotly_chart(fig_scatter, use_container_width=True)

            st.subheader("KtÃ³re czynniki sÄ… najwaÅ¼niejsze dla poczucia szczÄ™Å›cia?")
            numeric_cols = ['Happiness Score', 'GDP per capita', 'Social Support', 'Life Expectancy', 'Freedom',
                            'Generosity', 'Corruption']
            existing_cols = [col for col in numeric_cols if col in df_filtered.columns]
            if len(existing_cols) > 1:
                correlation_matrix = df_filtered[existing_cols].corr()
                fig_heatmap, ax = plt.subplots(figsize=(10, 8))
                sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', ax=ax)
                ax.set_title('Macierz korelacji czynnikÃ³w wpÅ‚ywajÄ…cych na szczÄ™Å›cie')
                st.pyplot(fig_heatmap)
else:
    # Ğ¡Ğ±Ñ€Ğ¾Ñ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ñ, ĞµÑĞ»Ğ¸ Ñ„Ğ°Ğ¹Ğ» Ğ±Ñ‹Ğ» Ğ²Ñ‹Ğ³Ñ€ÑƒĞ¶ĞµĞ½
    if 'data_cleaned' in st.session_state:
        del st.session_state['data_cleaned']
    st.info("ProszÄ™ przesÅ‚aÄ‡ plik CSV, aby rozpoczÄ…Ä‡ analizÄ™.")

# Uruchomienie aplikacji z terminala: streamlit run app.py
